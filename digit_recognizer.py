# -*- coding: utf-8 -*-
"""Digit_recognizer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BCGjvcXxitvmRdDyuGNbzEqODu_5mxJK
"""

# importing important libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from keras.layers import Dropout, Dense, Conv2D, AveragePooling2D, Flatten, MaxPooling2D
from keras.models import Sequential, load_model
from sklearn.metrics import accuracy_score

# Uploading train, data for prediction and sample submission file
train_data = pd.read_csv('train.csv')
prediction = pd.read_csv('test.csv')
submission1 = pd.read_csv('sample_submission.csv')

# Analysing train data
train_data.head()   # means a 28*28 image with numbers as label

# checking for any missiong values in training data
train_data.isnull().sum().sum()   # 0 missing values

# Splitting training set into initial training set and test set
train_data, test_data = train_test_split(train_data, stratify=train_data["label"], test_size = 0.20)

# Splitting initial training set into final training set and cross validation set
train_data, cv_data = train_test_split(train_data, stratify=train_data["label"], test_size = 0.25)
train_data.shape, test_data.shape, cv_data.shape

# Splitting the data into its label and features
train_y = train_data['label']
train_x = train_data.drop(columns = ['label'])
cv_y = cv_data['label']
cv_x = cv_data.drop(columns = ['label'])
test_y = test_data['label']
test_x = test_data.drop(columns = ['label'])

# Plotting the classification of each class in each dataset set

fig = plt.figure(figsize = (10, 6))
ax = fig.add_axes([0,0,1,1])
ax.set_title("Count of each class in training data", fontsize = 20)
sns.countplot(x = train_y)
for i in ax.patches:
    ax.text(x = i.get_x() + 0.2, y = i.get_height()+1.5, s = str(i.get_height()), fontsize = 20, color = "black")
plt.show()   
#####################################################################################################################
fig = plt.figure(figsize = (10, 6))
ax = fig.add_axes([0,0,1,1])
ax.set_title("Count of each class in cv data", fontsize = 20)
sns.countplot(x = cv_y)
for i in ax.patches:
    ax.text(x = i.get_x() + 0.2, y = i.get_height()+1.5, s = str(i.get_height()), fontsize = 20, color = "black")
plt.show() 
######################################################################################################################
fig = plt.figure(figsize = (10, 6))
ax = fig.add_axes([0,0,1,1])
ax.set_title("Count of each class in test data", fontsize = 20)
sns.countplot(x = test_y)
for i in ax.patches:
    ax.text(x = i.get_x() + 0.2, y = i.get_height()+1.5, s = str(i.get_height()), fontsize = 20, color = "black")
plt.show()

# Plotting a single training set to show how a training image looks like
x = np.array(train_x.iloc[0])
x = x.reshape(28,28)
plt.imshow(x)
print("The label according to training data is", train_y.iloc[0])   # As we can see that the image is same as label

# Changing the data into an array of pixels and labels so that it can be fed into the model expect test which is for prediction only
# Initially it was in the form of a DataFrame
train_x = np.array(train_x)
train_x = train_x.reshape(25200, 28, 28, 1)
train_y = np.array(pd.get_dummies(train_y))

cv_x = np.array(cv_x)
cv_x = cv_x.reshape(8400, 28, 28, 1)
cv_y = np.array(pd.get_dummies(cv_y))

# Changing the data into an array of pixels for test set
test_x = np.array(test_x)
test_x = test_x.reshape(8400, 28, 28, 1)

# Analyzing the data for prediction
prediction.head()

# Checking for any missing values in prediction data
prediction.isnull().sum().sum()   # 0 missing values

# To predict on prediction data we need to convert the this data also into an array of features
prediction = np.array(prediction)
prediction = t.reshape(28000, 28, 28, 1)

# Defining a model consisting of convolutional layers, polling layers and fully connected layer
def model():
    model = Sequential()
    model.add(Conv2D(32,kernel_size=3,activation='relu',input_shape=(28,28,1)))
    model.add(BatchNormalization())
    model.add(Conv2D(32,kernel_size=3,activation='relu'))
    model.add(BatchNormalization())
    model.add(Conv2D(32,kernel_size=5,strides=2,padding='same',activation='relu'))
    model.add(BatchNormalization())
    model.add(Dropout(0.4))
    model.add(Conv2D(64,kernel_size=3,activation='relu'))
    model.add(BatchNormalization())
    model.add(Conv2D(64,kernel_size=3,activation='relu'))
    model.add(BatchNormalization())
    model.add(Conv2D(64,kernel_size=5,strides=2,padding='same',activation='relu'))
    model.add(BatchNormalization())
    model.add(Dropout(0.4))
    model.add(Flatten())
    model.add(Dense(128, activation='relu'))
    model.add(BatchNormalization())
    model.add(Dropout(0.4))
    model.add(Dense(10, activation='softmax')) 
    
    return model
model = model()
model.summary()

# Compiling and running the model
model.compile(loss = 'categorical_crossentropy', optimizer = "adam", metrics = ["accuracy"])
hist = model.fit(train_x, train_y, validation_data=(cv_x, cv_y), epochs = 40)

# visualizing losses and accuracy with epochs 
epoch_number = []
for epoch in range(40):
    epoch_number.append(epoch + 1)
train_loss = hist.history['loss']
val_loss   = hist.history['val_loss']
train_acc  = hist.history['accuracy']
val_acc    = hist.history['val_accuracy']

# printing a table depicting the detail about the trained model
log_frame = pd.DataFrame(columns = ["Epoch", "Train_Loss", "Train_Accuracy", "CV_Loss", "CV_Accuracy"])
log_frame["Epoch"] = epoch_number
log_frame["Train_Loss"] = train_loss
log_frame["Train_Accuracy"] = train_acc
log_frame["CV_Loss"] = val_loss
log_frame["CV_Accuracy"] = val_acc 
log_frame

# plotting epoch vs loss
def plotting(epoch, train_loss, CV_loss, title):
    fig, axes = plt.subplots(1,1, figsize = (12, 8))
    axes.plot(epoch, train_loss, color = 'red', label = "Train")
    axes.plot(epoch, CV_loss, color = 'blue', label = "CV")
    axes.set_title(title, fontsize = 25)
    axes.set_xlabel("Epochs", fontsize = 20)
    axes.set_ylabel("Loss", fontsize = 20)
    axes.grid()
    axes.legend(fontsize = 20)

plotting(list(log_frame["Epoch"]), list(log_frame["Train_Loss"]), list(log_frame["CV_Loss"]), "EPOCH VS LOSS")

# plotting epoch vs accuracy
def plotting(epoch, train_acc, CV_acc, title):
    fig, axes = plt.subplots(1,1, figsize = (12, 8))
    axes.plot(epoch, train_acc, color = 'red', label = "Train_Accuracy")
    axes.plot(epoch, CV_acc, color = 'blue', label = "CV_Accuracy")
    axes.set_title(title, fontsize = 25)
    axes.set_xlabel("Epochs", fontsize = 20)
    axes.set_ylabel("Accuracy", fontsize = 20)
    axes.grid()
    axes.legend(fontsize = 20)

plotting(list(log_frame["Epoch"]), list(log_frame["Train_Accuracy"]), list(log_frame["CV_Accuracy"]), "EPOCH VS ACCURACY")

# predicting on test data
test_predict = model.predict(test_x)

# Since the test_predict is in the form of dummy variable with the value of probability so we will convert it into categorical data
l = []
for i in range(test_predict.shape[0]):
  j = test_predict[i].argmax()
  l.append(j)
test_predict = pd.DataFrame(l)

# Accuracy on test data
acc = accuracy_score(test_y, l) * 100
acc

# Now prediction on data to be predicted
prediction_predict = model.predict(prediction)

# Since the prediction_predict is in the form of dummy variable with the value of probability so we will convert it into categorical data
l = []
for i in range(prediction_predict.shape[0]):
  j = prediction_predict[i].argmax()
  l.append(j)
submission2 = pd.DataFrame(l)  
submission2 = submission2.rename(columns = {0 : 'Label'})

# Dropping the falsely labelled column from Sample submission file and clubing it with the predicted file 
submission1.drop(columns = ['Label'], inplace = True)
submission = pd.concat([submission1, submission2], axis = 1)

# Final submission file
submission

# Validation by image plotting
t = prediction.reshape(28000, 28, 28)
plt.imshow(t[2222])
print(" The label predicted is ", submission["Label"][2222])

# Saving the submission file
submission.to_csv('submission.csv')

